;; Object semanticdb-project-database-file
;; SEMANTICDB Tags save file
(semanticdb-project-database-file "semanticdb-project-database-file"
  :tables
  (list
    (semanticdb-table "semanticdb-table"
      :major-mode python-mode
      :tags 
        '( ("\"\"\"Operations for embeddings.\"\"\"" code nil nil [690 722])
            ("__future__" include nil nil [723 761])
            ("__future__" include nil nil [762 793])
            ("__future__" include nil nil [794 831])
            ("six.moves" include nil nil [833 861])
            ("tensorflow.python.framework" include nil nil [900 951])
            ("tensorflow.python.framework" include nil nil [952 998])
            ("tensorflow.python.framework" include nil nil [999 1042])
            ("tensorflow.python.framework" include nil nil [1043 1096])
            ("tensorflow.python.framework" include nil nil [1097 1149])
            ("tensorflow.python.ops" include nil nil [1150 1193])
            ("tensorflow.python.ops" include nil nil [1194 1236])
            ("tensorflow.python.ops" include nil nil [1269 1317])
            ("tensorflow.python.ops" include nil nil [1351 1398])
            ("tensorflow.python.ops" include nil nil [1399 1441])
            ("tensorflow.python.ops" include nil nil [1442 1497])
            ("tensorflow.python.ops" include nil nil [1498 1542])
            ("tensorflow.python.ops" include nil nil [1543 1586])
            ("tensorflow.python.platform" include nil nil [1587 1647])
            ("tensorflow.python.util.tf_export" include nil nil [1648 1702])
            ("_clip" function
               (:documentation "Helper function for _embedding_lookup_and_transform.

  This function optionally clips embeddings to an l2-norm of max_norm.

  Args:
    params: A `Tensor` of embeddings retrieved by `gather`.
    ids: The `ids` argument that was passed to `gather`.
    max_norm: If not `None`, each embedding is clipped if its l2-norm is
      larger than this value.

  Returns:
    A `Tensor` with the same type as `params`.
  "
                :arguments 
                  ( ("params" variable nil (reparse-symbol function_parameters) [1715 1721])
                    ("ids" variable nil (reparse-symbol function_parameters) [1723 1726])
                    ("max_norm" variable nil (reparse-symbol function_parameters) [1728 1736]))                  )
                nil [1705 2966])
            ("_embedding_lookup_and_transform" function
               (:documentation "Helper function for embedding_lookup and _compute_sampled_logits.

  This function is a generalization of embedding_lookup that optionally
  applies a caller-specified transformation to each embedding. This is
  done through the `transform_fn` argument. If provided, the function is
  applied to each partitioned tensor of retrieved embeddings, colocated
  with the embeddings. This function will be called with a single `Tensor`
  argument of the same type as the `params` tensor and should return a
  `Tensor`. The shape of the argument will be the same as `params` except
  for the size of the first dimension. The first dimension of the result's
  shape must be the same size as the argument's.

  Args:
    params: See embedding_lookup.
    ids: See embedding_lookup.
    partition_strategy: See embedding_lookup.
    name: See embedding_lookup.
    max_norm: See embedding_lookup.
    transform_fn: An optional function to apply to each retrieved embedding.
      If max_norm is provided, transform_fn is applied to the norm-limited
      embeddings.

  Returns:
    See embedding_lookup for details.
  Raises:
    ValueError: If `params` is empty.
  "
                :arguments 
                  ( ("params" variable nil (reparse-symbol function_parameters) [3004 3010])
                    ("ids" variable nil (reparse-symbol function_parameters) [3048 3051])
                    ("partition_strategy" variable nil (reparse-symbol function_parameters) [3089 3107])
                    ("name" variable nil (reparse-symbol function_parameters) [3151 3155])
                    ("max_norm" variable nil (reparse-symbol function_parameters) [3198 3206])
                    ("transform_fn" variable nil (reparse-symbol function_parameters) [3249 3261]))                  )
                nil [2968 10265])
            ("" code nil nil [10277 10300])
            ("embedding_lookup" function
               (:documentation "Looks up `ids` in a list of embedding tensors.

  This function is used to perform parallel lookups on the list of
  tensors in `params`.  It is a generalization of
  @{tf.gather}, where `params` is
  interpreted as a partitioning of a large embedding tensor.  `params` may be
  a `PartitionedVariable` as returned by using `tf.get_variable()` with a
  partitioner.

  If `len(params) > 1`, each element `id` of `ids` is partitioned between
  the elements of `params` according to the `partition_strategy`.
  In all strategies, if the id space does not evenly divide the number of
  partitions, each of the first `(max_id + 1) % len(params)` partitions will
  be assigned one more id.

  If `partition_strategy` is `\"mod\"`, we assign each id to partition
  `p = id % len(params)`. For instance,
  13 ids are split across 5 partitions as:
  `[[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]]`

  If `partition_strategy` is `\"div\"`, we assign ids to partitions in a
  contiguous manner. In this case, 13 ids are split across 5 partitions as:
  `[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]]`

  The results of the lookup are concatenated into a dense
  tensor. The returned tensor has shape `shape(ids) + shape(params)[1:]`.

  Args:
    params: A single tensor representing the complete embedding tensor,
      or a list of P tensors all of same shape except for the first dimension,
      representing sharded embedding tensors.  Alternatively, a
      `PartitionedVariable`, created by partitioning along dimension 0. Each
      element must be appropriately sized for the given `partition_strategy`.
    ids: A `Tensor` with type `int32` or `int64` containing the ids to be looked
      up in `params`.
    partition_strategy: A string specifying the partitioning strategy, relevant
      if `len(params) > 1`. Currently `\"div\"` and `\"mod\"` are supported. Default
      is `\"mod\"`.
    name: A name for the operation (optional).
    validate_indices: DEPRECATED. If this operation is assigned to CPU, values
      in `indices` are always validated to be within range.  If assigned to GPU,
      out-of-bound indices result in safe but unspecified behavior, which may
      include raising an error.
    max_norm: If not `None`, each embedding is clipped if its l2-norm is
      larger than this value.

  Returns:
    A `Tensor` with the same type as the tensors in `params`.

  Raises:
    ValueError: If `params` is empty.
  "
                :arguments 
                  ( ("params" variable nil (reparse-symbol function_parameters) [10327 10333])
                    ("ids" variable nil (reparse-symbol function_parameters) [10339 10342])
                    ("partition_strategy" variable nil (reparse-symbol function_parameters) [10348 10366])
                    ("name" variable nil (reparse-symbol function_parameters) [10378 10382])
                    ("validate_indices" variable nil (reparse-symbol function_parameters) [10393 10409])
                    ("max_norm" variable nil (reparse-symbol function_parameters) [10455 10463]))                  )
                nil [10301 13109])
            ("" code nil nil [13121 13151])
            ("embedding_lookup_sparse" function
               (:documentation "Computes embeddings for the given ids and weights.

  This op assumes that there is at least one id for each row in the dense tensor
  represented by sp_ids (i.e. there are no rows with empty features), and that
  all the indices of sp_ids are in canonical row-major order.

  It also assumes that all id values lie in the range [0, p0), where p0
  is the sum of the size of params along dimension 0.

  Args:
    params: A single tensor representing the complete embedding tensor,
      or a list of P tensors all of same shape except for the first dimension,
      representing sharded embedding tensors.  Alternatively, a
      `PartitionedVariable`, created by partitioning along dimension 0. Each
      element must be appropriately sized for the given `partition_strategy`.
    sp_ids: N x M `SparseTensor` of int64 ids where N is typically batch size
      and M is arbitrary.
    sp_weights: either a `SparseTensor` of float / double weights, or `None` to
      indicate all weights should be taken to be 1. If specified, `sp_weights`
      must have exactly the same shape and indices as `sp_ids`.
    partition_strategy: A string specifying the partitioning strategy, relevant
      if `len(params) > 1`. Currently `\"div\"` and `\"mod\"` are supported. Default
      is `\"mod\"`. See `tf.nn.embedding_lookup` for more details.
    name: Optional name for the op.
    combiner: A string specifying the reduction op. Currently \"mean\", \"sqrtn\"
      and \"sum\" are supported.
      \"sum\" computes the weighted sum of the embedding results for each row.
      \"mean\" is the weighted sum divided by the total weight.
      \"sqrtn\" is the weighted sum divided by the square root of the sum of the
      squares of the weights.
    max_norm: If not `None`, each embedding is clipped if its l2-norm is
      larger than this value, before combining.

  Returns:
    A dense tensor representing the combined embeddings for the
    sparse ids. For each row in the dense tensor represented by `sp_ids`, the op
    looks up the embeddings for all ids in that row, multiplies them by the
    corresponding weight, and combines these embeddings as specified.

    In other words, if

      `shape(combined params) = [p0, p1, ..., pm]`

    and

      `shape(sp_ids) = shape(sp_weights) = [d0, d1, ..., dn]`

    then

      `shape(output) = [d0, d1, ..., dn-1, p1, ..., pm]`.

    For instance, if params is a 10x20 matrix, and sp_ids / sp_weights are

      ```python
      [0, 0]: id 1, weight 2.0
      [0, 1]: id 3, weight 0.5
      [1, 0]: id 0, weight 1.0
      [2, 3]: id 1, weight 3.0
      ```

    with `combiner`=\"mean\", then the output will be a 3x20 matrix where

      ```python
      output[0, :] = (params[1, :] * 2.0 + params[3, :] * 0.5) / (2.0 + 0.5)
      output[1, :] = (params[0, :] * 1.0) / 1.0
      output[2, :] = (params[1, :] * 3.0) / 3.0
      ```

  Raises:
    TypeError: If `sp_ids` is not a `SparseTensor`, or if `sp_weights` is
      neither `None` nor `SparseTensor`.
    ValueError: If `combiner` is not one of {\"mean\", \"sqrtn\", \"sum\"}.
  "
                :arguments 
                  ( ("params" variable nil (reparse-symbol function_parameters) [13180 13186])
                    ("sp_ids" variable nil (reparse-symbol function_parameters) [13216 13222])
                    ("sp_weights" variable nil (reparse-symbol function_parameters) [13252 13262])
                    ("partition_strategy" variable nil (reparse-symbol function_parameters) [13292 13310])
                    ("name" variable nil (reparse-symbol function_parameters) [13346 13350])
                    ("combiner" variable nil (reparse-symbol function_parameters) [13385 13393])
                    ("max_norm" variable nil (reparse-symbol function_parameters) [13428 13436]))                  )
                nil [13152 20346])
            ("" code nil nil [20358 20393])
            ("safe_embedding_lookup_sparse" function
               (:documentation "Lookup embedding results, accounting for invalid IDs and empty features.

  The partitioned embedding in `embedding_weights` must all be the same shape
  except for the first dimension. The first dimension is allowed to vary as the
  vocabulary size is not necessarily a multiple of `P`.  `embedding_weights`
  may be a `PartitionedVariable` as returned by using `tf.get_variable()` with a
  partitioner.

  Invalid IDs (< 0) are pruned from input IDs and weights, as well as any IDs
  with non-positive weight. For an entry with no features, the embedding vector
  for `default_id` is returned, or the 0-vector if `default_id` is not supplied.

  The ids and weights may be multi-dimensional. Embeddings are always aggregated
  along the last dimension.

  Args:
    embedding_weights:  A list of `P` float `Tensor`s or values representing
        partitioned embedding `Tensor`s.  Alternatively, a `PartitionedVariable`
        created by partitioning along dimension 0.  The total unpartitioned
        shape should be `[e_0, e_1, ..., e_m]`, where `e_0` represents the
        vocab size and `e_1, ..., e_m` are the embedding dimensions.
    sparse_ids: `SparseTensor` of shape `[d_0, d_1, ..., d_n]` containing the
        ids. `d_0` is typically batch size.
    sparse_weights: `SparseTensor` of same shape as `sparse_ids`, containing
        float weights corresponding to `sparse_ids`, or `None` if all weights
        are be assumed to be 1.0.
    combiner: A string specifying how to combine embedding results for each
        entry. Currently \"mean\", \"sqrtn\" and \"sum\" are supported, with \"mean\"
        the default.
    default_id: The id to use for an entry with no features.
    name: A name for this operation (optional).
    partition_strategy: A string specifying the partitioning strategy.
        Currently `\"div\"` and `\"mod\"` are supported. Default is `\"div\"`.
    max_norm: If not `None`, all embeddings are l2-normalized to max_norm before
        combining.


  Returns:
    Dense `Tensor` of shape `[d_0, d_1, ..., d_{n-1}, e_1, ..., e_m]`.

  Raises:
    ValueError: if `embedding_weights` is empty.
  "
                :arguments 
                  ( ("embedding_weights" variable nil (reparse-symbol function_parameters) [20427 20444])
                    ("sparse_ids" variable nil (reparse-symbol function_parameters) [20479 20489])
                    ("sparse_weights" variable nil (reparse-symbol function_parameters) [20524 20538])
                    ("combiner" variable nil (reparse-symbol function_parameters) [20578 20586])
                    ("default_id" variable nil (reparse-symbol function_parameters) [20628 20638])
                    ("name" variable nil (reparse-symbol function_parameters) [20678 20682])
                    ("partition_strategy" variable nil (reparse-symbol function_parameters) [20722 20740])
                    ("max_norm" variable nil (reparse-symbol function_parameters) [20781 20789]))                  )
                nil [20394 26342])
            ("_prune_invalid_ids" function
               (:documentation "Prune invalid IDs (< 0) from the input ids and weights."
                :arguments 
                  ( ("sparse_ids" variable nil (reparse-symbol function_parameters) [26367 26377])
                    ("sparse_weights" variable nil (reparse-symbol function_parameters) [26379 26393]))                  )
                nil [26344 26895])
            ("_prune_invalid_weights" function
               (:documentation "Prune invalid weights (< 0) from the input ids and weights."
                :arguments 
                  ( ("sparse_ids" variable nil (reparse-symbol function_parameters) [26924 26934])
                    ("sparse_weights" variable nil (reparse-symbol function_parameters) [26936 26950]))                  )
                nil [26897 27308]))          
      :file "embedding_ops.py"
      :pointmax 27308
      :fsize 27307
      :lastmodtime '(23451 46871 145027 160000)
      :unmatched-syntax '((NAME 23383 . 23388) (IF 23412 . 23414) (ELSE 23442 . 23446)))
    (semanticdb-table "semanticdb-table"
      :major-mode python-mode
      :tags 
        '( ("\"\"\"Variable class.\"\"\"" code nil nil [690 711])
            ("__future__" include nil nil [712 750])
            ("__future__" include nil nil [751 782])
            ("__future__" include nil nil [783 820])
            ("tensorflow.core.framework" include nil nil [822 874])
            ("tensorflow.core.framework" include nil nil [875 925])
            ("tensorflow.python.eager" include nil nil [926 969])
            ("tensorflow.python.framework" include nil nil [970 1016])
            ("tensorflow.python.framework" include nil nil [1017 1060])
            ("tensorflow.python.framework" include nil nil [1061 1113])
            ("tensorflow.python.ops" include nil nil [1114 1157])
            ("tensorflow.python.ops" include nil nil [1158 1208])
            ("tensorflow.python.ops" include nil nil [1209 1256])
            ("tensorflow.python.ops" include nil nil [1257 1299])
            ("tensorflow.python.ops" include nil nil [1300 1343])
            ("tensorflow.python.platform" include nil nil [1344 1404])
            ("tensorflow.python.training.checkpointable" include nil nil [1405 1481])
            ("tensorflow.python.util" include nil nil [1482 1523])
            ("tensorflow.python.util" include nil nil [1524 1572])
            ("tensorflow.python.util.deprecation" include nil nil [1573 1630])
            ("tensorflow.python.util.tf_export" include nil nil [1631 1685])
            ("" code nil nil [1698 1710])
            ("Variable" type
               (:documentation "See the @{$variables$Variables How To} for a high level overview.

  A variable maintains state in the graph across calls to `run()`. You add a
  variable to the graph by constructing an instance of the class `Variable`.

  The `Variable()` constructor requires an initial value for the variable,
  which can be a `Tensor` of any type and shape. The initial value defines the
  type and shape of the variable. After construction, the type and shape of
  the variable are fixed. The value can be changed using one of the assign
  methods.

  If you want to change the shape of a variable later you have to use an
  `assign` Op with `validate_shape=False`.

  Just like any `Tensor`, variables created with `Variable()` can be used as
  inputs for other Ops in the graph. Additionally, all the operators
  overloaded for the `Tensor` class are carried over to variables, so you can
  also add nodes to the graph by just doing arithmetic on variables.

  ```python
  import tensorflow as tf

  # Create a variable.
  w = tf.Variable(<initial-value>, name=<optional-name>)

  # Use the variable in the graph like any Tensor.
  y = tf.matmul(w, ...another variable or tensor...)

  # The overloaded operators are available too.
  z = tf.sigmoid(w + y)

  # Assign a new value to the variable with `assign()` or a related method.
  w.assign(w + 1.0)
  w.assign_add(1.0)
  ```

  When you launch the graph, variables have to be explicitly initialized before
  you can run Ops that use their value. You can initialize a variable by
  running its *initializer op*, restoring the variable from a save file, or
  simply running an `assign` Op that assigns a value to the variable. In fact,
  the variable *initializer op* is just an `assign` Op that assigns the
  variable's initial value to the variable itself.

  ```python
  # Launch the graph in a session.
  with tf.Session() as sess:
      # Run the variable initializer.
      sess.run(w.initializer)
      # ...you now can run ops that use the value of 'w'...
  ```

  The most common initialization pattern is to use the convenience function
  `global_variables_initializer()` to add an Op to the graph that initializes
  all the variables. You then run that Op after launching the graph.

  ```python
  # Add an Op to initialize global variables.
  init_op = tf.global_variables_initializer()

  # Launch the graph in a session.
  with tf.Session() as sess:
      # Run the Op that initializes global variables.
      sess.run(init_op)
      # ...you can now run any Op that uses variable values...
  ```

  If you need to create a variable with an initial value dependent on another
  variable, use the other variable's `initialized_value()`. This ensures that
  variables are initialized in the right order.

  All variables are automatically collected in the graph where they are
  created. By default, the constructor adds the new variable to the graph
  collection `GraphKeys.GLOBAL_VARIABLES`. The convenience function
  `global_variables()` returns the contents of that collection.

  When building a machine learning model it is often convenient to distinguish
  between variables holding the trainable model parameters and other variables
  such as a `global step` variable used to count training steps. To make this
  easier, the variable constructor supports a `trainable=<bool>` parameter. If
  `True`, the new variable is also added to the graph collection
  `GraphKeys.TRAINABLE_VARIABLES`. The convenience function
  `trainable_variables()` returns the contents of this collection. The
  various `Optimizer` classes use this collection as the default list of
  variables to optimize.

  WARNING: tf.Variable objects have a non-intuitive memory model. A Variable is
  represented internally as a mutable Tensor which can non-deterministically
  alias other Tensors in a graph. The set of operations which consume a Variable
  and can lead to aliasing is undetermined and can change across TensorFlow
  versions. Avoid writing code which relies on the value of a Variable either
  changing or not changing as other operations happen. For example, using
  Variable objects or simple functions thereof as predicates in a `tf.cond` is
  dangerous and error-prone:

  ```
  v = tf.Variable(True)
  tf.cond(v, lambda: v.assign(False), my_false_fn)  # Note: this is broken.
  ```

  Here replacing tf.Variable with tf.contrib.eager.Variable will fix any
  nondeterminism issues.

  To use the replacement for variables which does
  not have these issues:

  * Replace `tf.Variable` with `tf.contrib.eager.Variable`;
  * Call `tf.get_variable_scope().set_use_resource(True)` inside a
    `tf.variable_scope` before the `tf.get_variable()` call.

  @compatibility(eager)
  `tf.Variable` is not compatible with eager execution.  Use
  `tf.contrib.eager.Variable` instead which is compatible with both eager
  execution and graph construction.  See [the TensorFlow Eager Execution
  guide](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/g3doc/guide.md#variables-and-optimizers)
  for details on how variables work in eager execution.
  @end_compatibility
  "
                :superclasses ("checkpointable.CheckpointableBase")
                :members 
                  ( ("__init__" function
                       (:suite 
                          ( ("\"\"\"Creates a new variable with value `initial_value`.

    The new variable is added to the graph collections listed in `collections`,
    which defaults to `[GraphKeys.GLOBAL_VARIABLES]`.

    If `trainable` is `True` the variable is also added to the graph collection
    `GraphKeys.TRAINABLE_VARIABLES`.

    This constructor creates both a `variable` Op and an `assign` Op to set the
    variable to its initial value.

    Args:
      initial_value: A `Tensor`, or Python object convertible to a `Tensor`,
        which is the initial value for the Variable. The initial value must have
        a shape specified unless `validate_shape` is set to False. Can also be a
        callable with no argument that returns the initial value when called. In
        that case, `dtype` must be specified. (Note that initializer functions
        from init_ops.py must first be bound to a shape before being used here.)
      trainable: If `True`, the default, also adds the variable to the graph
        collection `GraphKeys.TRAINABLE_VARIABLES`. This collection is used as
        the default list of variables to use by the `Optimizer` classes.
      collections: List of graph collections keys. The new variable is added to
        these collections. Defaults to `[GraphKeys.GLOBAL_VARIABLES]`.
      validate_shape: If `False`, allows the variable to be initialized with a
        value of unknown shape. If `True`, the default, the shape of
        `initial_value` must be known.
      caching_device: Optional device string describing where the Variable
        should be cached for reading.  Defaults to the Variable's device.
        If not `None`, caches on another device.  Typical use is to cache
        on the device where the Ops using the Variable reside, to deduplicate
        copying through `Switch` and other conditional statements.
      name: Optional name for the variable. Defaults to `'Variable'` and gets
        uniquified automatically.
      variable_def: `VariableDef` protocol buffer. If not `None`, recreates
        the Variable object with its contents, referencing the variable's nodes
        in the graph, which must already exist. The graph is not changed.
        `variable_def` and the other arguments are mutually exclusive.
      dtype: If set, initial_value will be converted to the given type.
        If `None`, either the datatype will be kept (if `initial_value` is
        a Tensor), or `convert_to_tensor` will decide.
      expected_shape: A TensorShape. If set, initial_value is expected
        to have this shape.
      import_scope: Optional `string`. Name scope to add to the
        `Variable.` Only used when initializing from protocol buffer.
      constraint: An optional projection function to be applied to the variable
        after being updated by an `Optimizer` (e.g. used to implement norm
        constraints or value constraints for layer weights). The function must
        take as input the unprojected Tensor representing the value of the
        variable and return the Tensor for the projected value
        (which must have the same shape). Constraints are not safe to
        use when doing asynchronous distributed training.

    Raises:
      ValueError: If both `variable_def` and initial_value are specified.
      ValueError: If the initial value is not specified, or does not have a
        shape and `validate_shape` is `True`.
      RuntimeError: If eager execution is enabled.

    @compatibility(eager)
    `tf.Variable` is not compatible with eager execution.  Use
    `tfe.Variable` instead which is compatible with both eager execution
    and graph construction.  See [the TensorFlow Eager Execution
    guide](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/g3doc/guide.md#variables-and-optimizers)
    for details on how variables work in eager execution.
    @end_compatibility
    \"\"\"" code nil (reparse-symbol indented_block_body) [7305 11215])
                            ("if" code nil (reparse-symbol indented_block_body) [11220 11408])
                            ("self" variable nil (reparse-symbol indented_block_body) [11412 11438])
                            ("if" code nil (reparse-symbol indented_block_body) [11443 12119]))                          
                        :parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [6934 6938])
                            ("initial_value" variable nil (reparse-symbol function_parameters) [6955 6968])
                            ("trainable" variable nil (reparse-symbol function_parameters) [6990 6999])
                            ("collections" variable nil (reparse-symbol function_parameters) [7021 7032])
                            ("validate_shape" variable nil (reparse-symbol function_parameters) [7054 7068])
                            ("caching_device" variable nil (reparse-symbol function_parameters) [7090 7104])
                            ("name" variable nil (reparse-symbol function_parameters) [7126 7130])
                            ("variable_def" variable nil (reparse-symbol function_parameters) [7152 7164])
                            ("dtype" variable nil (reparse-symbol function_parameters) [7186 7191])
                            ("expected_shape" variable nil (reparse-symbol function_parameters) [7213 7227])
                            ("import_scope" variable nil (reparse-symbol function_parameters) [7249 7261])
                            ("constraint" variable nil (reparse-symbol function_parameters) [7283 7293]))                          
                        :documentation "Creates a new variable with value `initial_value`.

    The new variable is added to the graph collections listed in `collections`,
    which defaults to `[GraphKeys.GLOBAL_VARIABLES]`.

    If `trainable` is `True` the variable is also added to the graph collection
    `GraphKeys.TRAINABLE_VARIABLES`.

    This constructor creates both a `variable` Op and an `assign` Op to set the
    variable to its initial value.

    Args:
      initial_value: A `Tensor`, or Python object convertible to a `Tensor`,
        which is the initial value for the Variable. The initial value must have
        a shape specified unless `validate_shape` is set to False. Can also be a
        callable with no argument that returns the initial value when called. In
        that case, `dtype` must be specified. (Note that initializer functions
        from init_ops.py must first be bound to a shape before being used here.)
      trainable: If `True`, the default, also adds the variable to the graph
        collection `GraphKeys.TRAINABLE_VARIABLES`. This collection is used as
        the default list of variables to use by the `Optimizer` classes.
      collections: List of graph collections keys. The new variable is added to
        these collections. Defaults to `[GraphKeys.GLOBAL_VARIABLES]`.
      validate_shape: If `False`, allows the variable to be initialized with a
        value of unknown shape. If `True`, the default, the shape of
        `initial_value` must be known.
      caching_device: Optional device string describing where the Variable
        should be cached for reading.  Defaults to the Variable's device.
        If not `None`, caches on another device.  Typical use is to cache
        on the device where the Ops using the Variable reside, to deduplicate
        copying through `Switch` and other conditional statements.
      name: Optional name for the variable. Defaults to `'Variable'` and gets
        uniquified automatically.
      variable_def: `VariableDef` protocol buffer. If not `None`, recreates
        the Variable object with its contents, referencing the variable's nodes
        in the graph, which must already exist. The graph is not changed.
        `variable_def` and the other arguments are mutually exclusive.
      dtype: If set, initial_value will be converted to the given type.
        If `None`, either the datatype will be kept (if `initial_value` is
        a Tensor), or `convert_to_tensor` will decide.
      expected_shape: A TensorShape. If set, initial_value is expected
        to have this shape.
      import_scope: Optional `string`. Name scope to add to the
        `Variable.` Only used when initializing from protocol buffer.
      constraint: An optional projection function to be applied to the variable
        after being updated by an `Optimizer` (e.g. used to implement norm
        constraints or value constraints for layer weights). The function must
        take as input the unprojected Tensor representing the value of the
        variable and return the Tensor for the projected value
        (which must have the same shape). Constraints are not safe to
        use when doing asynchronous distributed training.

    Raises:
      ValueError: If both `variable_def` and initial_value are specified.
      ValueError: If the initial value is not specified, or does not have a
        shape and `validate_shape` is `True`.
      RuntimeError: If eager execution is enabled.

    @compatibility(eager)
    `tf.Variable` is not compatible with eager execution.  Use
    `tfe.Variable` instead which is compatible with both eager execution
    and graph construction.  See [the TensorFlow Eager Execution
    guide](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/g3doc/guide.md#variables-and-optimizers)
    for details on how variables work in eager execution.
    @end_compatibility
    "
                        :constructor-flag t)
                        (reparse-symbol indented_block_body) [6921 12119])
                    ("__repr__" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [12135 12139]))                          )
                        (reparse-symbol indented_block_body) [12122 12509])
                    ("_init_from_args" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [12532 12536])
                            ("initial_value" variable nil (reparse-symbol function_parameters) [12560 12573])
                            ("trainable" variable nil (reparse-symbol function_parameters) [12602 12611])
                            ("collections" variable nil (reparse-symbol function_parameters) [12640 12651])
                            ("validate_shape" variable nil (reparse-symbol function_parameters) [12680 12694])
                            ("caching_device" variable nil (reparse-symbol function_parameters) [12723 12737])
                            ("name" variable nil (reparse-symbol function_parameters) [12766 12770])
                            ("dtype" variable nil (reparse-symbol function_parameters) [12799 12804])
                            ("expected_shape" variable nil (reparse-symbol function_parameters) [12833 12847])
                            ("constraint" variable nil (reparse-symbol function_parameters) [12876 12886]))                          
                        :documentation "Creates a new variable from arguments.

    Args:
      initial_value: A `Tensor`, or Python object convertible to a `Tensor`,
        which is the initial value for the Variable. The initial value must have
        a shape specified unless `validate_shape` is set to False. Can also be a
        callable with no argument that returns the initial value when called.
        (Note that initializer functions from init_ops.py must first be bound
         to a shape before being used here.)
      trainable: If `True`, the default, also adds the variable to the graph
        collection `GraphKeys.TRAINABLE_VARIABLES`. This collection is used as
        the default list of variables to use by the `Optimizer` classes.
      collections: List of graph collections keys. The new variable is added to
        these collections. Defaults to `[GraphKeys.GLOBAL_VARIABLES]`.
      validate_shape: If `False`, allows the variable to be initialized with a
        value of unknown shape. If `True`, the default, the shape of
        `initial_value` must be known.
      caching_device: Optional device string or function describing where the
        Variable should be cached for reading.  Defaults to the Variable's
        device.  If not `None`, caches on another device.  Typical use is to
        cache on the device where the Ops using the Variable reside, to
        deduplicate copying through `Switch` and other conditional statements.
      name: Optional name for the variable. Defaults to `'Variable'` and gets
        uniquified automatically.
      dtype: If set, initial_value will be converted to the given type.
        If None, either the datatype will be kept (if initial_value is
       a Tensor) or float32 will be used (if it is a Python object convertible
       to a Tensor).
      expected_shape: Deprecated. Ignored.
      constraint: An optional projection function to be applied to the variable
        after being updated by an `Optimizer` (e.g. used to implement norm
        constraints or value constraints for layer weights). The function must
        take as input the unprojected Tensor representing the value of the
        variable and return the Tensor for the projected value
        (which must have the same shape). Constraints are not safe to
        use when doing asynchronous distributed training.

    Raises:
      ValueError: If the initial value is not specified, or does not have a
        shape and `validate_shape` is `True`.
      RuntimeError: If lifted into the eager context.
    ")
                        (reparse-symbol indented_block_body) [12512 20680])
                    ("_init_from_proto" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [20704 20708])
                            ("variable_def" variable nil (reparse-symbol function_parameters) [20710 20722])
                            ("import_scope" variable nil (reparse-symbol function_parameters) [20724 20736]))                          
                        :documentation "Recreates the Variable object from a `VariableDef` protocol buffer.

    Args:
      variable_def: `VariableDef` protocol buffer, describing a variable
          whose nodes already exists in the graph.
      import_scope: Optional `string`. Name scope to add.
    ")
                        (reparse-symbol indented_block_body) [20683 22405])
                    ("_as_graph_element" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [22430 22434]))                          
                        :documentation "Conversion function for Graph.as_graph_element().")
                        (reparse-symbol indented_block_body) [22408 22523])
                    ("_AsTensor" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [22540 22544]))                          
                        :documentation "Converts this variable to a Tensor.

    See @{tf.Variable.value}.

    Returns:
      A `Tensor` containing the value of the variable.
    ")
                        (reparse-symbol indented_block_body) [22526 22756])
                    ("__iter__" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [22772 22776]))                          
                        :documentation "Dummy method to prevent iteration. Do not call.

    NOTE(mrry): If we register __getitem__ as an overloaded operator,
    Python will valiantly attempt to iterate over the variable's Tensor from 0
    to infinity.  Declaring this method prevents this unintended behavior.

    Raises:
      TypeError: when invoked.
    ")
                        (reparse-symbol indented_block_body) [22759 23169])
                    ("value" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [23182 23186]))                          
                        :documentation "Returns the last snapshot of this variable.

    You usually do not need to call this method as all ops that need the value
    of the variable call it automatically through a `convert_to_tensor()` call.

    Returns a `Tensor` which holds the value of the variable.  You can not
    assign a new value to this tensor as it is not a reference to the variable.

    To avoid copies, if the consumer of the returned value is on the same device
    as the variable, this actually returns the live value of the variable, not
    a copy.  Updates to the variable are seen by the consumer.  If the consumer
    is on a different device it will get a copy of the variable.

    Returns:
      A `Tensor` containing the value of the variable.
    ")
                        (reparse-symbol indented_block_body) [23172 23965])
                    ("read_value" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [23983 23987]))                          
                        :documentation "Returns the value of this variable, read in the current context.

    Can be different from value() if it's on another device, with control
    dependencies, etc.

    Returns:
      A `Tensor` containing the value of the variable.
    ")
                        (reparse-symbol indented_block_body) [23968 24296])
                    ("_ref" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [24308 24312]))                          
                        :documentation "Returns a reference to this variable.

    You usually do not need to call this method as all ops that need a reference
    to the variable call it automatically.

    Returns is a `Tensor` which holds a reference to the variable.  You can
    assign a new value to the variable by passing the tensor to an assign op.
    See @{tf.Variable.value} if you want to get the value of the
    variable.

    Returns:
      A `Tensor` that is a reference to the variable.
    ")
                        (reparse-symbol indented_block_body) [24299 24821])
                    ("set_shape" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [24838 24842])
                            ("shape" variable nil (reparse-symbol function_parameters) [24844 24849]))                          
                        :documentation "Overrides the shape for this variable.

    Args:
      shape: the `TensorShape` representing the overridden shape.
    ")
                        (reparse-symbol indented_block_body) [24824 25050])
                    ("trainable" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [25079 25083]))                          
                        :decorators 
                          ( ("property" function (:type "decorator") nil nil))                          )
                        (reparse-symbol indented_block_body) [25053 25113])
                    ("eval" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [25125 25129])
                            ("session" variable nil (reparse-symbol function_parameters) [25131 25138]))                          
                        :documentation "In a session, computes and returns the value of this variable.

    This is not a graph construction method, it does not add ops to the graph.

    This convenience method requires a session where the graph
    containing this variable has been launched. If no session is
    passed, the default session is used.  See @{tf.Session} for more
    information on launching a graph and on sessions.

    ```python
    v = tf.Variable([1, 2])
    init = tf.global_variables_initializer()

    with tf.Session() as sess:
        sess.run(init)
        # Usage passing the session explicitly.
        print(v.eval(sess))
        # Usage with the default session.  The 'with' block
        # above makes 'sess' the default session.
        print(v.eval())
    ```

    Args:
      session: The session to use to evaluate this variable. If
        none, the default session is used.

    Returns:
      A numpy `ndarray` with a copy of the value of this variable.
    ")
                        (reparse-symbol indented_block_body) [25116 26164])
                    ("initialized_value" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [26189 26193]))                          
                        :documentation "Returns the value of the initialized variable.

    You should use this instead of the variable itself to initialize another
    variable with a value that depends on the value of this variable.

    ```python
    # Initialize 'v' with a random tensor.
    v = tf.Variable(tf.truncated_normal([10, 40]))
    # Use `initialized_value` to guarantee that `v` has been
    # initialized before its value is used to initialize `w`.
    # The random values are picked only once.
    w = tf.Variable(v.initialized_value() * 2.0)
    ```

    Returns:
      A `Tensor` holding the value of this variable after its initializer
      has run.
    ")
                        (reparse-symbol indented_block_body) [26167 27052])
                    ("initial_value" function
                       (:parent "dummy"
                        :decorators 
                          ( ("property" function (:type "decorator") nil nil))                          
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [27085 27089]))                          
                        :documentation "Returns the Tensor used as the initial value for the variable.

    Note that this is different from `initialized_value()` which runs
    the op that initializes the variable before returning its value.
    This method returns the tensor that is used by the op that initializes
    the variable.

    Returns:
      A `Tensor`.
    ")
                        (reparse-symbol indented_block_body) [27055 27466])
                    ("constraint" function
                       (:parent "dummy"
                        :decorators 
                          ( ("property" function (:type "decorator") nil nil))                          
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [27496 27500]))                          
                        :documentation "Returns the constraint function associated with this variable.

    Returns:
      The constraint function that was passed to the variable constructor.
      Can be `None` if no constraint was passed.
    ")
                        (reparse-symbol indented_block_body) [27469 27747])
                    ("assign" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [27761 27765])
                            ("value" variable nil (reparse-symbol function_parameters) [27767 27772])
                            ("use_locking" variable nil (reparse-symbol function_parameters) [27774 27785]))                          
                        :documentation "Assigns a new value to the variable.

    This is essentially a shortcut for `assign(self, value)`.

    Args:
      value: A `Tensor`. The new value for this variable.
      use_locking: If `True`, use locking during the assignment.

    Returns:
      A `Tensor` that will hold the new value of this variable after
      the assignment has completed.
    ")
                        (reparse-symbol indented_block_body) [27750 28238])
                    ("assign_add" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [28256 28260])
                            ("delta" variable nil (reparse-symbol function_parameters) [28262 28267])
                            ("use_locking" variable nil (reparse-symbol function_parameters) [28269 28280]))                          
                        :documentation "Adds a value to this variable.

     This is essentially a shortcut for `assign_add(self, delta)`.

    Args:
      delta: A `Tensor`. The value to add to this variable.
      use_locking: If `True`, use locking during the operation.

    Returns:
      A `Tensor` that will hold the new value of this variable after
      the addition has completed.
    ")
                        (reparse-symbol indented_block_body) [28241 28735])
                    ("assign_sub" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [28753 28757])
                            ("delta" variable nil (reparse-symbol function_parameters) [28759 28764])
                            ("use_locking" variable nil (reparse-symbol function_parameters) [28766 28777]))                          
                        :documentation "Subtracts a value from this variable.

    This is essentially a shortcut for `assign_sub(self, delta)`.

    Args:
      delta: A `Tensor`. The value to subtract from this variable.
      use_locking: If `True`, use locking during the operation.

    Returns:
      A `Tensor` that will hold the new value of this variable after
      the subtraction has completed.
    ")
                        (reparse-symbol indented_block_body) [28738 29248])
                    ("scatter_sub" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [29267 29271])
                            ("sparse_delta" variable nil (reparse-symbol function_parameters) [29273 29285])
                            ("use_locking" variable nil (reparse-symbol function_parameters) [29287 29298]))                          
                        :documentation "Subtracts `IndexedSlices` from this variable.

    This is essentially a shortcut for `scatter_sub(self, sparse_delta.indices,
    sparse_delta.values)`.

    Args:
      sparse_delta: `IndexedSlices` to be subtracted from this variable.
      use_locking: If `True`, use locking during the operation.

    Returns:
      A `Tensor` that will hold the new value of this variable after
      the scattered subtraction has completed.

    Raises:
      ValueError: if `sparse_delta` is not an `IndexedSlices`.
    ")
                        (reparse-symbol indented_block_body) [29251 30115])
                    ("_strided_slice_assign" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [30144 30148])
                            ("begin" variable nil (reparse-symbol function_parameters) [30178 30183])
                            ("end" variable nil (reparse-symbol function_parameters) [30213 30216])
                            ("strides" variable nil (reparse-symbol function_parameters) [30246 30253])
                            ("value" variable nil (reparse-symbol function_parameters) [30283 30288])
                            ("name" variable nil (reparse-symbol function_parameters) [30318 30322])
                            ("begin_mask" variable nil (reparse-symbol function_parameters) [30352 30362])
                            ("end_mask" variable nil (reparse-symbol function_parameters) [30392 30400])
                            ("ellipsis_mask" variable nil (reparse-symbol function_parameters) [30430 30443])
                            ("new_axis_mask" variable nil (reparse-symbol function_parameters) [30473 30486])
                            ("shrink_axis_mask" variable nil (reparse-symbol function_parameters) [30516 30532]))                          )
                        (reparse-symbol indented_block_body) [30118 31256])
                    ("count_up_to" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [31275 31279])
                            ("limit" variable nil (reparse-symbol function_parameters) [31281 31286]))                          
                        :documentation "Increments this variable until it reaches `limit`.

    When that Op is run it tries to increment the variable by `1`. If
    incrementing the variable would bring it above `limit` then the Op raises
    the exception `OutOfRangeError`.

    If no error is raised, the Op outputs the value of the variable before
    the increment.

    This is essentially a shortcut for `count_up_to(self, limit)`.

    Args:
      limit: value at which incrementing the variable raises an error.

    Returns:
      A `Tensor` that will hold the variable value before the increment. If no
      other Op modifies this variable, the values produced will all be
      distinct.
    ")
                        (reparse-symbol indented_block_body) [31259 32028])
                    ("load" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [32040 32044])
                            ("value" variable nil (reparse-symbol function_parameters) [32046 32051])
                            ("session" variable nil (reparse-symbol function_parameters) [32053 32060]))                          
                        :documentation "Load new value into this variable.

    Writes new value to variable's memory. Doesn't add ops to the graph.

    This convenience method requires a session where the graph
    containing this variable has been launched. If no session is
    passed, the default session is used.  See @{tf.Session} for more
    information on launching a graph and on sessions.

    ```python
    v = tf.Variable([1, 2])
    init = tf.global_variables_initializer()

    with tf.Session() as sess:
        sess.run(init)
        # Usage passing the session explicitly.
        v.load([2, 3], sess)
        print(v.eval(sess)) # prints [2 3]
        # Usage with the default session.  The 'with' block
        # above makes 'sess' the default session.
        v.load([3, 4], sess)
        print(v.eval()) # prints [3 4]
    ```

    Args:
        value: New variable value
        session: The session to use to evaluate this variable. If
          none, the default session is used.

    Raises:
        ValueError: Session is not passed and no default session
    ")
                        (reparse-symbol indented_block_body) [32031 33498])
                    ("_TensorConversionFunction" function
                       (:typemodifiers ("static")
                        :decorators 
                          ( ("staticmethod" function (:type "decorator") nil nil))                          
                        :arguments 
                          ( ("v" variable nil (reparse-symbol function_parameters) [33573 33574])
                            ("dtype" variable nil (reparse-symbol function_parameters) [33576 33581])
                            ("name" variable nil (reparse-symbol function_parameters) [33588 33592])
                            ("as_ref" variable nil (reparse-symbol function_parameters) [33599 33605]))                          
                        :documentation "Utility function for converting a Variable to a Tensor.")
                        (reparse-symbol indented_block_body) [33527 34044])
                    ("_OverloadAllOperators" function
                       (:typemodifiers ("static")
                        :decorators 
                          ( ("staticmethod" function (:type "decorator") nil nil))                          
                        :documentation "Register overloads for all operators.")
                        (reparse-symbol indented_block_body) [34047 34466])
                    ("_OverloadOperator" function
                       (:typemodifiers ("static")
                        :decorators 
                          ( ("staticmethod" function (:type "decorator") nil nil))                          
                        :arguments 
                          ( ("operator" variable nil (reparse-symbol function_parameters) [34507 34515]))                          
                        :documentation "Defer an operator overload to `ops.Tensor`.

    We pull the operator out of ops.Tensor dynamically to avoid ordering issues.

    Args:
      operator: string. The operator name.
    ")
                        (reparse-symbol indented_block_body) [34469 35065])
                    ("_gather_saveables_for_checkpoint" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [35105 35109]))                          
                        :documentation "For implementing `Checkpointable`. This object is saveable on its own.")
                        (reparse-symbol indented_block_body) [35068 35246])
                    ("_try_guard_against_uninitialized_dependencies" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [35299 35303])
                            ("initial_value" variable nil (reparse-symbol function_parameters) [35305 35318]))                          
                        :documentation "Attempt to guard against dependencies on uninitialized variables.

    Replace references to variables in `initial_value` with references to the
    variable's initialized values. The initialized values are essentially
    conditional TensorFlow graphs that return a variable's value if it is
    initialized or its `initial_value` if it hasn't been initialized. This
    replacement is done on a best effort basis:

    - If the `initial_value` graph contains cycles, we don't do any
      replacements for that graph.
    - If the variables that `initial_value` depends on are not present in the
      `GLOBAL_VARIABLES` or `LOCAL_VARIABLES` we don't replace them.

    In these cases, it is up to the caller to ensure that the `initial_value`
    graph uses initialized variables or that they guard access to variables
    using their `initialized_value` method.

    Args:
      initial_value: `Tensor`. The initial value.
    Returns:
      A `Tensor` suitable to initialize a variable.
    Raises:
      TypeError: If `initial_value` is not a `Tensor`.
    ")
                        (reparse-symbol indented_block_body) [35249 37175])
                    ("_safe_initial_value_from_tensor" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [37214 37218])
                            ("tensor" variable nil (reparse-symbol function_parameters) [37220 37226])
                            ("op_cache" variable nil (reparse-symbol function_parameters) [37228 37236]))                          
                        :documentation "Replace dependencies on variables with their initialized values.

    Args:
      tensor: A `Tensor`. The tensor to replace.
      op_cache: A dict mapping operation names to `Operation`s. Used to memoize
        the results so as to avoid creating redundant operations.
    Returns:
      A `Tensor` compatible with `tensor`. Any inputs that lead to variable
      values will be replaced with a corresponding graph that uses the
      variable's initialized values. This is done on a best-effort basis. If no
      modifications need to be made then `tensor` will be returned unchanged.
    ")
                        (reparse-symbol indented_block_body) [37178 38061])
                    ("_safe_initial_value_from_op" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [38096 38100])
                            ("op" variable nil (reparse-symbol function_parameters) [38102 38104])
                            ("op_cache" variable nil (reparse-symbol function_parameters) [38106 38114]))                          
                        :documentation "Replace dependencies on variables with their initialized values.

    Args:
      op: An `Operation`. The operation to replace.
      op_cache: A dict mapping operation names to `Operation`s. Used to memoize
        the results so as to avoid creating redundant operations.
    Returns:
      An `Operation` compatible with `op`. Any inputs that lead to variable
      values will be replaced with a corresponding graph that uses the
      variable's initialized values. This is done on a best-effort basis. If no
      modifications need to be made then `op` will be returned unchanged.
    ")
                        (reparse-symbol indented_block_body) [38064 40006])
                    ("_find_initialized_value_for_variable" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [40050 40054])
                            ("variable_op" variable nil (reparse-symbol function_parameters) [40056 40067]))                          
                        :documentation "Find the initialized value for a variable op.

    To do so, lookup the variable op in the variables collection.

    Args:
      variable_op: A variable `Operation`.
    Returns:
      A `Tensor` representing the initialized value for the variable or `None`
      if the initialized value could not be found.
    ")
                        (reparse-symbol indented_block_body) [40009 40912])
                    ("__array_priority__" variable nil (reparse-symbol indented_block_body) [41291 41315])
                    ("name" function
                       (:parent "dummy"
                        :decorators 
                          ( ("property" function (:type "decorator") nil nil))                          
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [41340 41344]))                          
                        :documentation "The name of this variable.")
                        (reparse-symbol indented_block_body) [41319 41415])
                    ("_shared_name" function
                       (:parent "dummy"
                        :decorators 
                          ( ("property" function (:type "decorator") nil nil))                          
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [41447 41451]))                          
                        :documentation "The shared name of the variable.

      Unlike name(), shared_name doesn't have \":0\" suffix. It is user-specified
      name with name scope prefix.

    Returns:
      variable name.
    ")
                        (reparse-symbol indented_block_body) [41418 41679])
                    ("initializer" function
                       (:parent "dummy"
                        :decorators 
                          ( ("property" function (:type "decorator") nil nil))                          
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [41710 41714]))                          
                        :documentation "The initializer operation for this variable.")
                        (reparse-symbol indented_block_body) [41682 41804])
                    ("device" function
                       (:parent "dummy"
                        :decorators 
                          ( ("property" function (:type "decorator") nil nil))                          
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [41830 41834]))                          
                        :documentation "The device of this variable.")
                        (reparse-symbol indented_block_body) [41807 41909])
                    ("dtype" function
                       (:parent "dummy"
                        :decorators 
                          ( ("property" function (:type "decorator") nil nil))                          
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [41934 41938]))                          
                        :documentation "The `DType` of this variable.")
                        (reparse-symbol indented_block_body) [41912 42013])
                    ("op" function
                       (:parent "dummy"
                        :decorators 
                          ( ("property" function (:type "decorator") nil nil))                          
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [42035 42039]))                          
                        :documentation "The `Operation` of this variable.")
                        (reparse-symbol indented_block_body) [42016 42115])
                    ("graph" function
                       (:parent "dummy"
                        :decorators 
                          ( ("property" function (:type "decorator") nil nil))                          
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [42140 42144]))                          
                        :documentation "The `Graph` of this variable.")
                        (reparse-symbol indented_block_body) [42118 42219])
                    ("shape" function
                       (:parent "dummy"
                        :decorators 
                          ( ("property" function (:type "decorator") nil nil))                          
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [42244 42248]))                          
                        :documentation "The `TensorShape` of this variable.

    Returns:
      A `TensorShape`.
    ")
                        (reparse-symbol indented_block_body) [42222 42377])
                    ("get_shape" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [42394 42398]))                          
                        :documentation "Alias of Variable.shape.")
                        (reparse-symbol indented_block_body) [42380 42458])
                    ("to_proto" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [42474 42478])
                            ("export_scope" variable nil (reparse-symbol function_parameters) [42480 42492]))                          
                        :documentation "Converts a `Variable` to a `VariableDef` protocol buffer.

    Args:
      export_scope: Optional `string`. Name scope to remove.

    Returns:
      A `VariableDef` protocol buffer, or `None` if the `Variable` is not
      in the specified name scope.
    ")
                        (reparse-symbol indented_block_body) [42461 43626])
                    ("from_proto" function
                       (:typemodifiers ("static")
                        :decorators 
                          ( ("staticmethod" function (:type "decorator") nil nil))                          
                        :arguments 
                          ( ("variable_def" variable nil (reparse-symbol function_parameters) [43660 43672])
                            ("import_scope" variable nil (reparse-symbol function_parameters) [43674 43686]))                          
                        :documentation "Returns a `Variable` object created from `variable_def`.")
                        (reparse-symbol indented_block_body) [43629 43855])
                    ("__iadd__" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [43871 43875])
                            ("other" variable nil (reparse-symbol function_parameters) [43877 43882]))                          )
                        (reparse-symbol indented_block_body) [43858 44148])
                    ("__isub__" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [44164 44168])
                            ("other" variable nil (reparse-symbol function_parameters) [44170 44175]))                          )
                        (reparse-symbol indented_block_body) [44151 44441])
                    ("__imul__" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [44457 44461])
                            ("other" variable nil (reparse-symbol function_parameters) [44463 44468]))                          )
                        (reparse-symbol indented_block_body) [44444 44740])
                    ("__idiv__" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [44756 44760])
                            ("other" variable nil (reparse-symbol function_parameters) [44762 44767]))                          )
                        (reparse-symbol indented_block_body) [44743 45039])
                    ("__itruediv__" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [45059 45063])
                            ("other" variable nil (reparse-symbol function_parameters) [45065 45070]))                          )
                        (reparse-symbol indented_block_body) [45042 45342])
                    ("__irealdiv__" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [45362 45366])
                            ("other" variable nil (reparse-symbol function_parameters) [45368 45373]))                          )
                        (reparse-symbol indented_block_body) [45345 45645])
                    ("__ipow__" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [45661 45665])
                            ("other" variable nil (reparse-symbol function_parameters) [45667 45672]))                          )
                        (reparse-symbol indented_block_body) [45648 45948])
                    ("SaveSliceInfo" type
                       (:documentation "Information on how to save this Variable as a slice.

    Provides internal support for saving variables as slices of a larger
    variable.  This API is not public and is subject to change.

    Available properties:

    * full_name
    * full_shape
    * var_offset
    * var_shape
    "
                        :superclasses ("object")
                        :members 
                          ( ("__init__" function
                               (:suite 
                                  ( ("\"\"\"Create a `SaveSliceInfo`.

      Args:
        full_name: Name of the full variable of which this `Variable` is a
            slice.
        full_shape: Shape of the full variable, as a list of int.
        var_offset: Offset of this `Variable` into the full variable, as a
            list of int.
        var_shape: Shape of this `Variable`, as a list of int.
        save_slice_info_def: `SaveSliceInfoDef` protocol buffer. If not `None`,
          recreates the SaveSliceInfo object its contents.
          `save_slice_info_def` and other arguments are mutually
          exclusive.
        import_scope: Optional `string`. Name scope to add. Only used
          when initializing from protocol buffer.
      \"\"\"" code nil (reparse-symbol indented_block_body) [46524 47243])
                                    ("if" code nil (reparse-symbol indented_block_body) [47250 47835]))                                  
                                :parent "dummy"
                                :arguments 
                                  ( ("self" variable nil (reparse-symbol function_parameters) [46298 46302])
                                    ("full_name" variable nil (reparse-symbol function_parameters) [46321 46330])
                                    ("full_shape" variable nil (reparse-symbol function_parameters) [46354 46364])
                                    ("var_offset" variable nil (reparse-symbol function_parameters) [46388 46398])
                                    ("var_shape" variable nil (reparse-symbol function_parameters) [46422 46431])
                                    ("save_slice_info_def" variable nil (reparse-symbol function_parameters) [46455 46474])
                                    ("import_scope" variable nil (reparse-symbol function_parameters) [46498 46510]))                                  
                                :documentation "Create a `SaveSliceInfo`.

      Args:
        full_name: Name of the full variable of which this `Variable` is a
            slice.
        full_shape: Shape of the full variable, as a list of int.
        var_offset: Offset of this `Variable` into the full variable, as a
            list of int.
        var_shape: Shape of this `Variable`, as a list of int.
        save_slice_info_def: `SaveSliceInfoDef` protocol buffer. If not `None`,
          recreates the SaveSliceInfo object its contents.
          `save_slice_info_def` and other arguments are mutually
          exclusive.
        import_scope: Optional `string`. Name scope to add. Only used
          when initializing from protocol buffer.
      "
                                :constructor-flag t)
                                (reparse-symbol indented_block_body) [46285 47835])
                            ("spec" function
                               (:parent "dummy"
                                :decorators 
                                  ( ("property" function (:type "decorator") nil nil))                                  
                                :arguments 
                                  ( ("self" variable nil (reparse-symbol function_parameters) [47863 47867]))                                  
                                :documentation "Computes the spec string used for saving.")
                                (reparse-symbol indented_block_body) [47840 48149])
                            ("to_proto" function
                               (:parent "dummy"
                                :arguments 
                                  ( ("self" variable nil (reparse-symbol function_parameters) [48167 48171])
                                    ("export_scope" variable nil (reparse-symbol function_parameters) [48173 48185]))                                  
                                :documentation "Returns a SaveSliceInfoDef() proto.

      Args:
        export_scope: Optional `string`. Name scope to remove.

      Returns:
        A `SaveSliceInfoDef` protocol buffer, or None if the `Variable` is not
        in the specified name scope.
      ")
                                (reparse-symbol indented_block_body) [48154 49028]))                          
                        :type "class")
                        (reparse-symbol indented_block_body) [45951 49028])
                    ("_set_save_slice_info" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [49056 49060])
                            ("save_slice_info" variable nil (reparse-symbol function_parameters) [49062 49077]))                          
                        :documentation "Sets the slice info for this `Variable`.

    Args:
      save_slice_info: A `Variable.SaveSliceInfo` object.
    ")
                        (reparse-symbol indented_block_body) [49031 49249])
                    ("_get_save_slice_info" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [49277 49281]))                          )
                        (reparse-symbol indented_block_body) [49252 49317]))                  
                :type "class")
                nil [1711 49317])
            ("PartitionedVariable" type
               (:documentation "A container for partitioned `Variable` objects.

  @compatibility(eager) `tf.PartitionedVariable` is not compatible with
  eager execution.  Use `tfe.Variable` instead which is compatible
  with both eager execution and graph construction.  See [the
  TensorFlow Eager Execution
  guide](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/g3doc/guide.md#variables-and-optimizers)
  for details on how variables work in eager execution.
  @end_compatibility
  "
                :superclasses ("object")
                :members 
                  ( ("PartitionedVariableIterator" type
                       (:documentation "An iterator that allows accessing the underlying `Variable` objects.

    This iterator is necessary to control order of access when Variables
    are not partitioned in a standard way along a single axis.

    Allows e.g. `list(partitioned_variable)` to return a proper list.
    "
                        :superclasses ("object")
                        :members 
                          ( ("__init__" function
                               (:suite 
                                  ( ("self" variable nil (reparse-symbol indented_block_body) [50247 50259])
                                    ("self" variable nil (reparse-symbol indented_block_body) [50266 50315]))                                  
                                :parent "dummy"
                                :arguments 
                                  ( ("self" variable nil (reparse-symbol function_parameters) [50212 50216])
                                    ("partitioned_variable" variable nil (reparse-symbol function_parameters) [50218 50238]))                                  
                                :constructor-flag t)
                                (reparse-symbol indented_block_body) [50199 50316])
                            ("__iter__" function
                               (:parent "dummy"
                                :arguments 
                                  ( ("self" variable nil (reparse-symbol function_parameters) [50334 50338]))                                  )
                                (reparse-symbol indented_block_body) [50321 50359])
                            ("__next__" function
                               (:parent "dummy"
                                :arguments 
                                  ( ("self" variable nil (reparse-symbol function_parameters) [50377 50381]))                                  )
                                (reparse-symbol indented_block_body) [50364 50439])
                            ("next" function
                               (:parent "dummy"
                                :arguments 
                                  ( ("self" variable nil (reparse-symbol function_parameters) [50453 50457]))                                  )
                                (reparse-symbol indented_block_body) [50444 50751]))                          
                        :type "class")
                        (reparse-symbol indented_block_body) [49859 50751])
                    ("__init__" function
                       (:suite 
                          ( ("\"\"\"Creates a new partitioned variable wrapper.

    Variables passed via the variable_list must contain a save_slice_info
    field.  Concatenation and iteration is in lexicographic order according
    to the var_offset property of the save_slice_info.

    Args:
      name: String. Overall name of the variables.
      shape: List of integers.  Overall shape of the variables.
      dtype: Type of the variables.
      variable_list: List of `Variable` that comprise this partitioned variable.
      partitions: List of integers.  Number of partitions for each dimension.

    Raises:
      TypeError: If `variable_list` is not a list of `Variable` objects, or
        `partitions` is not a list.
      ValueError: If `variable_list` is empty, or the `Variable` shape
        information does not match `shape`, or `partitions` has invalid values.
      RuntimeError: If eager execution is enabled
    \"\"\"" code nil (reparse-symbol indented_block_body) [50825 51732])
                            ("if" code nil (reparse-symbol indented_block_body) [51737 51875])
                            ("if" code nil (reparse-symbol indented_block_body) [51879 52021])
                            ("if" code nil (reparse-symbol indented_block_body) [52025 52147])
                            ("if" code nil (reparse-symbol indented_block_body) [52151 52270])
                            ("if" code nil (reparse-symbol indented_block_body) [52274 52353])
                            ("for" code nil (reparse-symbol indented_block_body) [52396 53142])
                            ("self" variable nil (reparse-symbol indented_block_body) [53146 53249])
                            ("self" variable nil (reparse-symbol indented_block_body) [53293 53310])
                            ("self" variable nil (reparse-symbol indented_block_body) [53315 53334])
                            ("self" variable nil (reparse-symbol indented_block_body) [53339 53358])
                            ("self" variable nil (reparse-symbol indented_block_body) [53363 53392])
                            ("self" variable nil (reparse-symbol indented_block_body) [53397 53419]))                          
                        :parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [50767 50771])
                            ("name" variable nil (reparse-symbol function_parameters) [50773 50777])
                            ("shape" variable nil (reparse-symbol function_parameters) [50779 50784])
                            ("dtype" variable nil (reparse-symbol function_parameters) [50786 50791])
                            ("variable_list" variable nil (reparse-symbol function_parameters) [50793 50806])
                            ("partitions" variable nil (reparse-symbol function_parameters) [50808 50818]))                          
                        :documentation "Creates a new partitioned variable wrapper.

    Variables passed via the variable_list must contain a save_slice_info
    field.  Concatenation and iteration is in lexicographic order according
    to the var_offset property of the save_slice_info.

    Args:
      name: String. Overall name of the variables.
      shape: List of integers.  Overall shape of the variables.
      dtype: Type of the variables.
      variable_list: List of `Variable` that comprise this partitioned variable.
      partitions: List of integers.  Number of partitions for each dimension.

    Raises:
      TypeError: If `variable_list` is not a list of `Variable` objects, or
        `partitions` is not a list.
      ValueError: If `variable_list` is empty, or the `Variable` shape
        information does not match `shape`, or `partitions` has invalid values.
      RuntimeError: If eager execution is enabled
    "
                        :constructor-flag t)
                        (reparse-symbol indented_block_body) [50754 53420])
                    ("__iter__" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [53436 53440]))                          
                        :documentation "Return an iterable for accessing the underlying partition Variables.")
                        (reparse-symbol indented_block_body) [53423 53572])
                    ("__len__" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [53587 53591]))                          )
                        (reparse-symbol indented_block_body) [53575 53830])
                    ("_partition_axes" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [53853 53857]))                          )
                        (reparse-symbol indented_block_body) [53833 54001])
                    ("_concat" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [54016 54020]))                          
                        :documentation "Returns the overall concatenated value as a `Tensor`.

    This is different from using the partitioned variable directly as a tensor
    (through tensor conversion and `as_tensor`) in that it creates a new set of
    operations that keeps the control dependencies from its scope.

    Returns:
      `Tensor` containing the concatenated value.
    ")
                        (reparse-symbol indented_block_body) [54004 55054])
                    ("as_tensor" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [55071 55075]))                          
                        :documentation "Returns the overall concatenated value as a `Tensor`.

    The returned tensor will not inherit the control dependencies from the scope
    where the value is used, which is similar to getting the value of
    `Variable`.

    Returns:
      `Tensor` containing the concatenated value.
    ")
                        (reparse-symbol indented_block_body) [55057 55448])
                    ("_TensorConversionFunction" function
                       (:typemodifiers ("static")
                        :arguments 
                          ( ("v" variable nil (reparse-symbol function_parameters) [55497 55498])
                            ("dtype" variable nil (reparse-symbol function_parameters) [55500 55505])
                            ("name" variable nil (reparse-symbol function_parameters) [55512 55516])
                            ("as_ref" variable nil (reparse-symbol function_parameters) [55523 55529]))                          
                        :decorators 
                          ( ("staticmethod" function (:type "decorator") nil nil))                          )
                        (reparse-symbol indented_block_body) [55451 55972])
                    ("name" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [55996 56000]))                          
                        :decorators 
                          ( ("property" function (:type "decorator") nil nil))                          )
                        (reparse-symbol indented_block_body) [55975 56025])
                    ("dtype" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [56050 56054]))                          
                        :decorators 
                          ( ("property" function (:type "decorator") nil nil))                          )
                        (reparse-symbol indented_block_body) [56028 56080])
                    ("shape" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [56105 56109]))                          
                        :decorators 
                          ( ("property" function (:type "decorator") nil nil))                          )
                        (reparse-symbol indented_block_body) [56083 56140])
                    ("get_shape" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [56157 56161]))                          )
                        (reparse-symbol indented_block_body) [56143 56187])
                    ("_get_variable_list" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [56213 56217]))                          )
                        (reparse-symbol indented_block_body) [56190 56251])
                    ("_get_partitions" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [56274 56278]))                          )
                        (reparse-symbol indented_block_body) [56254 56309])
                    ("assign" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [56323 56327])
                            ("value" variable nil (reparse-symbol function_parameters) [56329 56334])
                            ("use_locking" variable nil (reparse-symbol function_parameters) [56336 56347]))                          )
                        (reparse-symbol indented_block_body) [56312 56484]))                  
                :type "class")
                nil [49319 56484])
            ("" code nil nil [56496 56516])
            ("global_variables" function
               (:documentation "Returns global variables.

  Global variables are variables that are shared across machines in a
  distributed environment. The `Variable()` constructor or `get_variable()`
  automatically adds new variables to the graph collection
  `GraphKeys.GLOBAL_VARIABLES`.
  This convenience function returns the contents of that collection.

  An alternative to global variables are local variables. See
  @{tf.local_variables}

  Args:
    scope: (Optional.) A string. If supplied, the resulting list is filtered
      to include only items whose `name` attribute matches `scope` using
      `re.match`. Items without a `name` attribute are never returned if a
      scope is supplied. The choice of `re.match` means that a `scope` without
      special tokens filters by prefix.

  Returns:
    A list of `Variable` objects.
  "
                :arguments 
                  ( ("scope" variable nil (reparse-symbol function_parameters) [56538 56543]))                  )
                nil [56517 57448])
            ("" code nil nil [57460 57477])
            ("" code nil nil [57489 57546])
            ("all_variables" function (:documentation "See `tf.global_variables`.") nil [57547 57631])
            ("_all_saveable_objects" function
               (:documentation "Returns all variables and `SaveableObject`s that must be checkpointed.

  Args:
    scope: (Optional.) A string. If supplied, the resulting list is filtered
      to include only items whose `name` attribute matches `scope` using
      `re.match`. Items without a `name` attribute are never returned if a
      scope is supplied. The choice of `re.match` means that a `scope` without
      special tokens filters by prefix.

  Returns:
    A list of `Variable` and `SaveableObject` to be checkpointed
  "
                :arguments 
                  ( ("scope" variable nil (reparse-symbol function_parameters) [57659 57664]))                  )
                nil [57633 58395])
            ("" code nil nil [58407 58426])
            ("local_variables" function
               (:documentation "Returns local variables.

  Local variables - per process variables, usually not saved/restored to
  checkpoint and used for temporary or intermediate values.
  For example, they can be used as counters for metrics computation or
  number of epochs this machine has read data.
  The `tf.contrib.framework.local_variable()` function automatically adds the
  new variable to `GraphKeys.LOCAL_VARIABLES`.
  This convenience function returns the contents of that collection.

  An alternative to local variables are global variables. See
  @{tf.global_variables}

  Args:
    scope: (Optional.) A string. If supplied, the resulting list is filtered
      to include only items whose `name` attribute matches `scope` using
      `re.match`. Items without a `name` attribute are never returned if a
      scope is supplied. The choice of `re.match` means that a `scope` without
      special tokens filters by prefix.

  Returns:
    A list of local `Variable` objects.
  "
                :arguments 
                  ( ("scope" variable nil (reparse-symbol function_parameters) [58447 58452]))                  )
                nil [58427 59501])
            ("" code nil nil [59513 59532])
            ("model_variables" function
               (:documentation "Returns all variables in the MODEL_VARIABLES collection.

  Args:
    scope: (Optional.) A string. If supplied, the resulting list is filtered
      to include only items whose `name` attribute matches `scope` using
      `re.match`. Items without a `name` attribute are never returned if a
      scope is supplied. The choice of `re.match` means that a `scope` without
      special tokens filters by prefix.

  Returns:
    A list of local Variable objects.
  "
                :arguments 
                  ( ("scope" variable nil (reparse-symbol function_parameters) [59553 59558]))                  )
                nil [59533 60103])
            ("" code nil nil [60115 60138])
            ("trainable_variables" function
               (:documentation "Returns all variables created with `trainable=True`.

  When passed `trainable=True`, the `Variable()` constructor automatically
  adds new variables to the graph collection
  `GraphKeys.TRAINABLE_VARIABLES`. This convenience function returns the
  contents of that collection.

  Args:
    scope: (Optional.) A string. If supplied, the resulting list is filtered
      to include only items whose `name` attribute matches `scope` using
      `re.match`. Items without a `name` attribute are never returned if a
      scope is supplied. The choice of `re.match` means that a `scope` without
      special tokens filters by prefix.

  Returns:
    A list of Variable objects.
  "
                :arguments 
                  ( ("scope" variable nil (reparse-symbol function_parameters) [60163 60168]))                  )
                nil [60139 60932])
            ("" code nil nil [60944 60972])
            ("moving_average_variables" function
               (:documentation "Returns all variables that maintain their moving averages.

  If an `ExponentialMovingAverage` object is created and the `apply()`
  method is called on a list of variables, these variables will
  be added to the `GraphKeys.MOVING_AVERAGE_VARIABLES` collection.
  This convenience function returns the contents of that collection.

  Args:
    scope: (Optional.) A string. If supplied, the resulting list is filtered
      to include only items whose `name` attribute matches `scope` using
      `re.match`. Items without a `name` attribute are never returned if a
      scope is supplied. The choice of `re.match` means that a `scope` without
      special tokens filters by prefix.

  Returns:
    A list of Variable objects.
  "
                :arguments 
                  ( ("scope" variable nil (reparse-symbol function_parameters) [61002 61007]))                  )
                nil [60973 61829])
            ("" code nil nil [61841 61892])
            ("variables_initializer" function
               (:documentation "Returns an Op that initializes a list of variables.

  After you launch the graph in a session, you can run the returned Op to
  initialize all the variables in `var_list`. This Op runs all the
  initializers of the variables in `var_list` in parallel.

  Calling `initialize_variables()` is equivalent to passing the list of
  initializers to `Group()`.

  If `var_list` is empty, however, the function still returns an Op that can
  be run. That Op just has no effect.

  Args:
    var_list: List of `Variable` objects to initialize.
    name: Optional name for the returned operation.

  Returns:
    An Op that run the initializers of all the specified variables.
  "
                :arguments 
                  ( ("var_list" variable nil (reparse-symbol function_parameters) [61919 61927])
                    ("name" variable nil (reparse-symbol function_parameters) [61929 61933]))                  )
                nil [61893 62797])
            ("" code nil nil [62809 62833])
            ("" code nil nil [62878 62935])
            ("initialize_variables" function
               (:documentation "See `tf.variables_initializer`."
                :arguments 
                  ( ("var_list" variable nil (reparse-symbol function_parameters) [62961 62969])
                    ("name" variable nil (reparse-symbol function_parameters) [62971 62975]))                  )
                nil [62936 63077])
            ("" code nil nil [63089 63154])
            ("global_variables_initializer" function (:documentation "Returns an Op that initializes global variables.

  This is just a shortcut for `variables_initializer(global_variables())`

  Returns:
    An Op that initializes global variables in the graph.
  ") nil [63155 63552])
            ("" code nil nil [63564 63592])
            ("" code nil nil [63637 63701])
            ("initialize_all_variables" function (:documentation "See `tf.global_variables_initializer`.") nil [63702 63821])
            ("" code nil nil [63833 63896])
            ("local_variables_initializer" function (:documentation "Returns an Op that initializes all local variables.

  This is just a shortcut for `variables_initializer(local_variables())`

  Returns:
    An Op that initializes all local variables in the graph.
  ") nil [63897 64296])
            ("" code nil nil [64308 64338])
            ("" code nil nil [64383 64446])
            ("initialize_local_variables" function (:documentation "See `tf.local_variables_initializer`.") nil [64447 64566])
            ("" code nil nil [64578 64605])
            ("is_variable_initialized" function
               (:documentation "Tests if a variable has been initialized.

  Args:
    variable: A `Variable`.

  Returns:
    Returns a scalar boolean Tensor, `True` if the variable has been
    initialized, `False` otherwise.
  "
                :arguments 
                  ( ("variable" variable nil (reparse-symbol function_parameters) [64667 64675]))                  
                :decorators 
                  ( ("tf_should_use.should_use_result" function (:type "decorator") nil nil))                  )
                nil [64606 64938])
            ("" code nil nil [64950 64982])
            ("assert_variables_initialized" function
               (:documentation "Returns an Op to check if variables are initialized.

  NOTE: This function is obsolete and will be removed in 6 months.  Please
  change your implementation to use `report_uninitialized_variables()`.

  When run, the returned Op will raise the exception `FailedPreconditionError`
  if any of the variables has not yet been initialized.

  Note: This function is implemented by trying to fetch the values of the
  variables. If one of the variables is not initialized a message may be
  logged by the C++ runtime. This is expected.

  Args:
    var_list: List of `Variable` objects to check. Defaults to the
      value of `global_variables().`

  Returns:
    An Op, or None if there are no variables.
  "
                :arguments 
                  ( ("var_list" variable nil (reparse-symbol function_parameters) [65049 65057]))                  
                :decorators 
                  ( ("tf_should_use.should_use_result" function (:type "decorator") nil nil))                  )
                nil [64983 66412])
            ("" code nil nil [66424 66458])
            ("report_uninitialized_variables" function
               (:documentation "Adds ops to list the names of uninitialized variables.

  When run, it returns a 1-D tensor containing the names of uninitialized
  variables if there are any, or an empty array if there are none.

  Args:
    var_list: List of `Variable` objects to check. Defaults to the
      value of `global_variables() + local_variables()`
    name: Optional name of the `Operation`.

  Returns:
    A 1-D tensor containing names of the uninitialized variables, or an empty
    1-D tensor if there are no variables or no uninitialized variables.
  "
                :arguments 
                  ( ("var_list" variable nil (reparse-symbol function_parameters) [66527 66535])
                    ("name" variable nil (reparse-symbol function_parameters) [66577 66581]))                  
                :decorators 
                  ( ("tf_should_use.should_use_result" function (:type "decorator") nil nil))                  )
                nil [66459 68429])
            ("Variable" code nil nil [68465 68497])
            ("ops" code nil nil [68499 68611])
            ("ops" code nil nil [68648 68693]))          
      :file "variables.py"
      :pointmax 68694
      :fsize 68693
      :lastmodtime '(23451 46871 165025 472000)
      :unmatched-syntax '((RETURN 39149 . 39155) (IF 39159 . 39161) (ELSE 39188 . 39192) (INDENT_BLOCK 17694 . 17954) (NEWLINE 17693 . 17694) (COLON 17692 . 17693) (WITH 17640 . 17644) (COMMA 17674 . 17675)))
    (semanticdb-table "semanticdb-table"
      :major-mode python-mode
      :tags 
        '( ("\"\"\"Operations for clipping (gradient, weight) tensors to min/max values.\"\"\"" code nil nil [691 766])
            ("__future__" include nil nil [767 805])
            ("__future__" include nil nil [806 837])
            ("__future__" include nil nil [838 875])
            ("collections" include nil nil [877 895])
            ("six" include nil nil [897 907])
            ("tensorflow.python.framework" include nil nil [909 960])
            ("tensorflow.python.framework" include nil nil [961 1007])
            ("tensorflow.python.framework" include nil nil [1008 1051])
            ("tensorflow.python.ops" include nil nil [1052 1095])
            ("tensorflow.python.ops" include nil nil [1096 1143])
            ("tensorflow.python.ops" include nil nil [1144 1188])
            ("tensorflow.python.ops" include nil nil [1189 1231])
            ("tensorflow.python.util.tf_export" include nil nil [1232 1286])
            ("" code nil nil [1299 1316])
            ("clip_by_value" function
               (:documentation "Clips tensor values to a specified min and max.

  Given a tensor `t`, this operation returns a tensor of the same type and
  shape as `t` with its values clipped to `clip_value_min` and `clip_value_max`.
  Any values less than `clip_value_min` are set to `clip_value_min`. Any values
  greater than `clip_value_max` are set to `clip_value_max`.

  Args:
    t: A `Tensor`.
    clip_value_min: A 0-D (scalar) `Tensor`, or a `Tensor` with the same shape
      as `t`. The minimum value to clip by.
    clip_value_max: A 0-D (scalar) `Tensor`, or a `Tensor` with the same shape
      as `t`. The maximum value to clip by.
    name: A name for the operation (optional).

  Returns:
    A clipped `Tensor`.

  Raises:
    ValueError: if the clip tensors would trigger array broadcasting
      that would make the returned tensor larger than the input.
  "
                :arguments 
                  ( ("t" variable nil (reparse-symbol function_parameters) [1335 1336])
                    ("clip_value_min" variable nil (reparse-symbol function_parameters) [1338 1352])
                    ("clip_value_max" variable nil (reparse-symbol function_parameters) [1354 1368])
                    ("name" variable nil (reparse-symbol function_parameters) [1388 1392]))                  )
                nil [1317 2804])
            ("_clip_by_value_grad" function
               (:documentation "Returns grad of clip_by_value."
                :arguments 
                  ( ("op" variable nil (reparse-symbol function_parameters) [3092 3094])
                    ("grad" variable nil (reparse-symbol function_parameters) [3096 3100]))                  )
                nil [3068 3934])
            ("" code nil nil [3946 3962])
            ("clip_by_norm" function
               (:documentation "Clips tensor values to a maximum L2-norm.

  Given a tensor `t`, and a maximum clip value `clip_norm`, this operation
  normalizes `t` so that its L2-norm is less than or equal to `clip_norm`,
  along the dimensions given in `axes`. Specifically, in the default case
  where all dimensions are used for calculation, if the L2-norm of `t` is
  already less than or equal to `clip_norm`, then `t` is not modified. If
  the L2-norm is greater than `clip_norm`, then this operation returns a
  tensor of the same type and shape as `t` with its values set to:

  `t * clip_norm / l2norm(t)`

  In this case, the L2-norm of the output tensor is `clip_norm`.

  As another example, if `t` is a matrix and `axes == [1]`, then each row
  of the output will have L2-norm equal to `clip_norm`. If `axes == [0]`
  instead, each column of the output will be clipped.

  This operation is typically used to clip gradients before applying them with
  an optimizer.

  Args:
    t: A `Tensor`.
    clip_norm: A 0-D (scalar) `Tensor` > 0. A maximum clipping value.
    axes: A 1-D (vector) `Tensor` of type int32 containing the dimensions
      to use for computing the L2-norm. If `None` (the default), uses all
      dimensions.
    name: A name for the operation (optional).

  Returns:
    A clipped `Tensor`.
  "
                :arguments 
                  ( ("t" variable nil (reparse-symbol function_parameters) [3980 3981])
                    ("clip_norm" variable nil (reparse-symbol function_parameters) [3983 3992])
                    ("axes" variable nil (reparse-symbol function_parameters) [3994 3998])
                    ("name" variable nil (reparse-symbol function_parameters) [4005 4009]))                  )
                nil [3963 5896])
            ("" code nil nil [5908 5923])
            ("global_norm" function
               (:documentation "Computes the global norm of multiple tensors.

  Given a tuple or list of tensors `t_list`, this operation returns the
  global norm of the elements in all tensors in `t_list`. The global norm is
  computed as:

  `global_norm = sqrt(sum([l2norm(t)**2 for t in t_list]))`

  Any entries in `t_list` that are of type None are ignored.

  Args:
    t_list: A tuple or list of mixed `Tensors`, `IndexedSlices`, or None.
    name: A name for the operation (optional).

  Returns:
    A 0-D (scalar) `Tensor` of type `float`.

  Raises:
    TypeError: If `t_list` is not a sequence.
  "
                :arguments 
                  ( ("t_list" variable nil (reparse-symbol function_parameters) [5940 5946])
                    ("name" variable nil (reparse-symbol function_parameters) [5948 5952]))                  )
                nil [5924 7407])
            ("" code nil nil [7419 7442])
            ("clip_by_global_norm" function
               (:documentation "Clips values of multiple tensors by the ratio of the sum of their norms.

  Given a tuple or list of tensors `t_list`, and a clipping ratio `clip_norm`,
  this operation returns a list of clipped tensors `list_clipped`
  and the global norm (`global_norm`) of all tensors in `t_list`. Optionally,
  if you've already computed the global norm for `t_list`, you can specify
  the global norm with `use_norm`.

  To perform the clipping, the values `t_list[i]` are set to:

      t_list[i] * clip_norm / max(global_norm, clip_norm)

  where:

      global_norm = sqrt(sum([l2norm(t)**2 for t in t_list]))

  If `clip_norm > global_norm` then the entries in `t_list` remain as they are,
  otherwise they're all shrunk by the global ratio.

  Any of the entries of `t_list` that are of type `None` are ignored.

  This is the correct way to perform gradient clipping (for example, see
  [Pascanu et al., 2012](http://arxiv.org/abs/1211.5063)
  ([pdf](http://arxiv.org/pdf/1211.5063.pdf))).

  However, it is slower than `clip_by_norm()` because all the parameters must be
  ready before the clipping operation can be performed.

  Args:
    t_list: A tuple or list of mixed `Tensors`, `IndexedSlices`, or None.
    clip_norm: A 0-D (scalar) `Tensor` > 0. The clipping ratio.
    use_norm: A 0-D (scalar) `Tensor` of type `float` (optional). The global
      norm to use. If not provided, `global_norm()` is used to compute the norm.
    name: A name for the operation (optional).

  Returns:
    list_clipped: A list of `Tensors` of the same type as `list_t`.
    global_norm: A 0-D (scalar) `Tensor` representing the global norm.

  Raises:
    TypeError: If `t_list` is not a sequence.
  "
                :arguments 
                  ( ("t_list" variable nil (reparse-symbol function_parameters) [7467 7473])
                    ("clip_norm" variable nil (reparse-symbol function_parameters) [7475 7484])
                    ("use_norm" variable nil (reparse-symbol function_parameters) [7486 7494])
                    ("name" variable nil (reparse-symbol function_parameters) [7501 7505]))                  )
                nil [7443 10462])
            ("" code nil nil [10474 10498])
            ("clip_by_average_norm" function
               (:documentation "Clips tensor values to a maximum average L2-norm.

  Given a tensor `t`, and a maximum clip value `clip_norm`, this operation
  normalizes `t` so that its average L2-norm is less than or equal to
  `clip_norm`. Specifically, if the average L2-norm is already less than or
  equal to `clip_norm`, then `t` is not modified. If the average L2-norm is
  greater than `clip_norm`, then this operation returns a tensor of the same
  type and shape as `t` with its values set to:

  `t * clip_norm / l2norm_avg(t)`

  In this case, the average L2-norm of the output tensor is `clip_norm`.

  This operation is typically used to clip gradients before applying them with
  an optimizer.

  Args:
    t: A `Tensor`.
    clip_norm: A 0-D (scalar) `Tensor` > 0. A maximum clipping value.
    name: A name for the operation (optional).

  Returns:
    A clipped `Tensor`.
  "
                :arguments 
                  ( ("t" variable nil (reparse-symbol function_parameters) [10524 10525])
                    ("clip_norm" variable nil (reparse-symbol function_parameters) [10527 10536])
                    ("name" variable nil (reparse-symbol function_parameters) [10538 10542]))                  )
                nil [10499 11997]))          
      :file "clip_ops.py"
      :pointmax 11997
      :fsize 11996
      :lastmodtime '(23451 46871 145027 160000)
      :unmatched-syntax nil))
  :file "!home!kevingeng!anaconda3!lib!python3.6!site-packages!tensorflow!python!ops!semantic.cache"
  :semantic-tag-version "2.0"
  :semanticdb-version "2.2")
